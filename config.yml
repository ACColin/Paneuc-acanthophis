#######################################################################
#                           Metadata files                            #
#######################################################################
metadata:
  runlib2samp_file: "rawdata/metadata/runlib2sample.tsv"
  sample_meta_file: "rawdata/metadata/samples.tsv"
  setfile_glob: "rawdata/metadata/samplesets/*.txt"


#######################################################################
#                           Raw Fastq Data                            #
#######################################################################
# Paths to raw data. These should be consistent across all samples. Samples
# must have either an R1 and R2, or an interleaved (il) fastq file per run and
# library. Having both is an error. If you somehow end up with both, combine
# the R1 & R2 files and append them to the interleaved, then remove the
# original R1/R2 files.
raw_paths:
  r1_path: "rawdata/reads/{run}/{lib}_R1.fastq.gz"
  r2_path: "rawdata/reads/{run}/{lib}_R2.fastq.gz"
  il_path: "rawdata/reads/{run}/{lib}_il.fastq.gz"


#######################################################################
#                          Reference Genomes                          #
#######################################################################
refs:
  Egrandis_phytozome13_v2:
    # For each reference we need a gff and a genome fasta file.
    # The genome fasta file must be faidx-indexed **BEFORE** the pipeline is
    # run. Other indexes (e.g. bwa, ngm) are run as part of the pipeline, but
    # the pipeline code needs to know the lengths of chromosomes before it
    # runs, so for now you must `samtools faidx` each fasta file you put here
    # manually ahead of running snakemake.
    fasta: "rawdata/references/Egrandis_phytozome13_v2.0/Egrandis_297_v2.0.softmasked.fa"
    gff: "rawdata/references/Egrandis_phytozome13_v2.0/Egrandis_297_v2.0.gene_exons.gff3"
    # For snpEff, we need two other bits of metadata. The organism name (which
    # is used in snpEff reports), and any additional lines of config in the
    # snpEff.config file for this reference. This is where one should specificy
    # custom translation codes etc.  See the snpEff documentation.
    organism: Eucalyptus grandis
    snpeff_extra_config: ""


#######################################################################
#                               Read QC                               #
#######################################################################
qc:
  _DEFAULT_:
    # _DEFAULT_ describes the settings to use for all runs except those
    # specifically named below.
    #
    # The below settings match the NEB NextTera oligos.
    # First two are RC of last two, swapped. Not sure what's correct
    #adapter1: AATGATACGGCGACCACCGAGATCTACACNNNNNNNNTCGTCGGCAGCGTCAGATGTGTATAAGAGACAG
    #adapter2: CAAGCAGAAGACGGCATACGAGATNNNNNNNNGTCTCGTGGGCTCGGAGATGTGTATAAGAGACAG
    adapter1: CTGTCTCTTATACACATCTCCGAGCCCACGAGACNNNNNNNNATCTCGTATGCCGTCTTCTGCTTG
    adapter2: CTGTCTCTTATACACATCTGACGCTGCCGACGANNNNNNNNGTGTAGATCTCGGTGGTCGCCGTATCATT
    minqual: 20



#######################################################################
#                               Kraken                                #
#######################################################################
kraken:
  dburls:
    PlusPFP: "https://genome-idx.s3.amazonaws.com/kraken/k2_pluspfp_20210127.tar.gz"
    PlusPFP16: "https://genome-idx.s3.amazonaws.com/kraken/k2_pluspfp_16gb_20210127.tar.gz"
  samplesets:
    HBDecra:
      - PlusPFP16


#######################################################################
#                               Multiqc                               #
#######################################################################
multiqc:
  HBDecra:
    - rawreads
    - samplereads
    - bamstats
    - kraken


#######################################################################
#                       Alignment to Reference                        #
#######################################################################
align:
  aligners:
    - bwa
  refs:
    - Egrandis_phytozome13_v2
  samplesets:
    - HBDecra
  ngm: # tool specific settings
    sensitivity: 0.5
  abra2:
    java_args: '-Xmx16G'


#######################################################################
#                   Non-gatk-based Variant Calling                    #
#######################################################################
varcall:
  
  # Per-aligner minimum MAPQ thresholds for using a read.
  minmapq:
    bwa: 30  # bwa scores approximately follow a PHRED scale (-10*log10(p))
    ngm: 10  # NGM scores are bonkers, and don't follow a particularly clear scale. in practice ~10 seems appropriate

  # Minimum base quality to count *base* in pileup
  minbq: 15 
  
  # Chunk size for parallisation across genome. Per variant caller as they take
  # have different runtime and memory requirements, and all need to fit in
  # ~12hours on a single job.
  chunksize:
    mpileup:   2000000
    freebayes:   50000
    gatk-hc: 100000000

  # The main per-sample set configuration. Here we select which variant
  # callers, aligners, and reference genomes get used, and set some parameters
  # specific to each sample set.
  samplesets:
    HBDecra:
      theta_prior: 0.001
      aligners:
        - bwa
      callers:
        - mpileup
      refs:
        - Egrandis_phytozome13_v2
      filters:
        - default
      snpeff: True

  # Filters. These are series of command line arguments to pass to bcftools
  # view. These filters apply while multiallelic variants have been decomposed
  # into multiple overlapping variant calls. This allows e.g. allele frequency
  # filters to be performed on a per-allele basis.
  filters:
    default: >
      -i 'QUAL >= 10 &&
          ALT != "." &&
          INFO/DP >= 5 &&
          INFO/AN >= 3'

#######################################################################
#                        Cluster Configuration                        #
#######################################################################
# Here one can set the resources each job will request from the cluster. 
cluster_resources:
  #DEBUG: True  # this will dump all the 
  defaults:
    mem_gb: 2
    time_min: 60
    queue: normal
  max_values:
    mem_gb: 192
    time_min: 2880 # 48h
  rules:
    # A mapping of rule_name: resource overrides, e.g.
    # qcreads:
    #   mem_gb: 192
    #   time_min: 2880 # 48h
    rawreads_from_il:
      time_min: 30
    rawreads_from_r1r2:
      time_min: 30
    bam_markdups_sort:
      localdisk_gb: 200
    kraken:
      time_min: 60
